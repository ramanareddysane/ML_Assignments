{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_sst = pd.read_csv('preprocessed_reviews_SST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>perfect dark chocol experi</td>\n",
       "      <td>well dark chocol creami lavend absolut perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>fresh qualiti</td>\n",
       "      <td>swear cupcak ate fresh one local groceri store...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>wrong</td>\n",
       "      <td>origin given 1 star sinc cake best shape got s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>cat like juic food</td>\n",
       "      <td>cat love sauc wet food feed product sauci winn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                     Summary  \\\n",
       "0      5  perfect dark chocol experi   \n",
       "1      5               fresh qualiti   \n",
       "2      5                       wrong   \n",
       "3      5          cat like juic food   \n",
       "\n",
       "                                                Text  \n",
       "0  well dark chocol creami lavend absolut perfect...  \n",
       "1  swear cupcak ate fresh one local groceri store...  \n",
       "2  origin given 1 star sinc cake best shape got s...  \n",
       "3  cat love sauc wet food feed product sauci winn...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sst[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['smry_txt'] = reviews_sst['Summary'].astype(str) + ' ' + reviews_sst['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['score'] = reviews_sst['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smry_txt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perfect dark chocol experi well dark chocol cr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fresh qualiti swear cupcak ate fresh one local...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wrong origin given 1 star sinc cake best shape...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat like juic food cat love sauc wet food feed...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list mislead cocoa butter found reason thought...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            smry_txt  score\n",
       "0  perfect dark chocol experi well dark chocol cr...      5\n",
       "1  fresh qualiti swear cupcak ate fresh one local...      5\n",
       "2  wrong origin given 1 star sinc cake best shape...      5\n",
       "3  cat like juic food cat love sauc wet food feed...      5\n",
       "4  list mislead cocoa butter found reason thought...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets filter the dataset so that it contains reviews that are either positive(4 or 5) or negative(1 or 2)\n",
    "dataset = dataset[dataset.score != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525814, 2)\n",
      "42640 rows has review as 3\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print('{} rows has review as 3'.format(568454 - 525814))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['score'] = dataset['score'].apply({1:'negative', 2:'negative', 4:'positive', 5:'positive'}.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smry_txt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perfect dark chocol experi well dark chocol cr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fresh qualiti swear cupcak ate fresh one local...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wrong origin given 1 star sinc cake best shape...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat like juic food cat love sauc wet food feed...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list mislead cocoa butter found reason thought...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            smry_txt     score\n",
       "0  perfect dark chocol experi well dark chocol cr...  positive\n",
       "1  fresh qualiti swear cupcak ate fresh one local...  positive\n",
       "2  wrong origin given 1 star sinc cake best shape...  positive\n",
       "3  cat like juic food cat love sauc wet food feed...  positive\n",
       "4  list mislead cocoa butter found reason thought...  negative"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the training(70%) and testing(30%) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def getTrainAndTestIndices(size, trn_pcnt = 0.70, tst_pcnt = 0.30):\n",
    "    print(\"\\n we have {} datapoints\".format(size), end = \". \")\n",
    "    train_size = int(size*trn_pcnt)\n",
    "    test_size = size - train_size\n",
    "    print(\"Out of which, we will get {} points in our training data and {} points in our testing data. \\n\".format(train_size, test_size))\n",
    "    ind = list(range(size))\n",
    "    random.shuffle(ind)\n",
    "    return ind[:train_size], ind[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " we have 525814 datapoints. Out of which, we will get 368069 points in our training data and 157745 points in our testing data. \n",
      "\n"
     ]
    }
   ],
   "source": [
    " trn_ind, tst_ind = getTrainAndTestIndices(dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368069, 157745)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_ind), len(tst_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((368069, 2), (157745, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset.iloc[trn_ind]\n",
    "test_data = dataset.iloc[tst_ind]\n",
    "train_data.shape, test_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smry_txt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488256</th>\n",
       "      <td>favorit coffe recent treat keurig singl serv m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329626</th>\n",
       "      <td>great vanilla flavor weak first time purchas p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smry_txt     score\n",
       "488256  favorit coffe recent treat keurig singl serv m...  positive\n",
       "329626  great vanilla flavor weak first time purchas p...  positive"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating word count Sparse vector representation of Training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts = count_vectorizer.fit_transform(train_data['smry_txt'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix,\n",
       " <368069x70903 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 12282295 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_counts), word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets see how sparse matrix looks like\n",
    "# print(word_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test = test_data['smry_txt'].values, test_data['score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb_classifier = MultinomialNB()\n",
    "multi_nb_classifier.fit(X=word_counts, y=train_data['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multi_nb_classifier.predict(count_vectorizer.transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['positive', 'positive', 'positive', 'positive', 'positive',\n",
       "        'positive', 'positive', 'positive', 'positive', 'positive'], \n",
       "       dtype='<U8'),\n",
       " array(['positive', 'positive', 'positive', 'positive', 'positive',\n",
       "        'positive', 'positive', 'positive', 'positive', 'positive'], dtype=object))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:10], y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9189324542774732\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(pred == np.array(y_test)) / len(pred)\n",
    "print('accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.73      0.75      0.74     24542\n",
      "   positive       0.95      0.95      0.95    133203\n",
      "\n",
      "avg / total       0.92      0.92      0.92    157745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91893245427747317, 0.91893245427747317, 0.91893245427747317, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating F1_score using function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# intialize confusion matrix\n",
    "confusion_matrix = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_confusion_matrix(predicted, actual):\n",
    "    \n",
    "#     if(predicted == 'positive' and actual == 'positive'):\n",
    "#         print(predicted, actual)\n",
    "    if predicted == actual and actual == 'positive':\n",
    "        # update true positives\n",
    "        confusion_matrix.update({'TP':1})\n",
    "    elif predicted == actual and actual == 'negative':\n",
    "        # update true negatives\n",
    "        confusion_matrix.update({'TN':1})\n",
    "    elif predicted != actual and actual == 'positive':\n",
    "        # update false negatives\n",
    "        confusion_matrix.update({'FN':1})\n",
    "    elif predicted != actual and actual == 'negative':\n",
    "        # update false positives\n",
    "        confusion_matrix.update({'FP':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'FN': 6667, 'FP': 6121, 'TN': 18421, 'TP': 126536})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix.clear()\n",
    "for tp in zip(pred, y_test):\n",
    "    update_confusion_matrix(str(tp[0]), str(tp[1]))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.953858446972\n",
      "recall: 0.949948574732\n",
      "F score : 0.951899495975\n"
     ]
    }
   ],
   "source": [
    "precision = confusion_matrix['TP']/(confusion_matrix['TP'] + confusion_matrix['FP'])\n",
    "print('Precision:{0:.12f}'.format(precision))\n",
    "\n",
    "recall = confusion_matrix['TP']/(confusion_matrix['TP']+confusion_matrix['FN'])\n",
    "print('recall: {0:.12f}'.format(recall))\n",
    "\n",
    "f_score = 2*(precision*recall)/(precision+recall)\n",
    "print('F score : {0:.12f}'.format(f_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
