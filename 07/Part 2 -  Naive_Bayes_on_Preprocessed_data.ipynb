{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This csv file contains Score, Summary and Text as preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_sst = pd.read_csv('preprocessed_reviews_SST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>perfect dark chocol experi</td>\n",
       "      <td>well dark chocol creami lavend absolut perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>fresh qualiti</td>\n",
       "      <td>swear cupcak ate fresh one local groceri store...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>wrong</td>\n",
       "      <td>origin given 1 star sinc cake best shape got s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                     Summary  \\\n",
       "0      5  perfect dark chocol experi   \n",
       "1      5               fresh qualiti   \n",
       "2      5                       wrong   \n",
       "\n",
       "                                                Text  \n",
       "0  well dark chocol creami lavend absolut perfect...  \n",
       "1  swear cupcak ate fresh one local groceri store...  \n",
       "2  origin given 1 star sinc cake best shape got s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sst[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568454"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = reviews_sst.shape[0]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397917\n",
      "170537\n"
     ]
    }
   ],
   "source": [
    "train_size = int(rows*0.70)\n",
    "test_size = rows - train_size\n",
    "\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating new dataframes for train aand test data\n",
    "train_data = pd.DataFrame(columns=reviews_sst.columns)\n",
    "test_data  = pd.DataFrame(columns=reviews_sst.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data : Empty DataFrame\n",
      "Columns: [Score, Summary, Text]\n",
      "Index: []\n",
      "\n",
      "Test Data: Empty DataFrame\n",
      "Columns: [Score, Summary, Text]\n",
      "Index: []\n",
      "\n",
      "test_size : 170537 train_size : 397917\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data : {}\".format(train_data))\n",
    "print(\"\\nTest Data: {}\".format(test_data))\n",
    "print(\"\\ntest_size : {} train_size : {}\".format(test_size, train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156487, 293844, 61513, 45757, 178260, 6156, 218695, 275897, 381294, 77095]\n",
      "[44856, 280988, 309808, 135195, 15138, 62155, 79897, 538523, 159837, 398555]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# indices list contains all indices from 0 to rows..\n",
    "indices =list(range(rows))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# get random indices from shuffled indices array for train and test data..\n",
    "trnind = indices[:train_size]\n",
    "tstind = indices[train_size:rows]\n",
    "\n",
    "print(trnind[:10])\n",
    "print(tstind[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into train and test based on the indices that we saperated\n",
    "train_data = reviews_sst.iloc[trnind]\n",
    "test_data = reviews_sst.iloc[tstind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156487</th>\n",
       "      <td>5</td>\n",
       "      <td>excel snack bar</td>\n",
       "      <td>tast first fiber one bar thought run head eart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score          Summary  \\\n",
       "156487      5  excel snack bar   \n",
       "\n",
       "                                                     Text  \n",
       "156487  tast first fiber one bar thought run head eart...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44856</th>\n",
       "      <td>5</td>\n",
       "      <td>like creami good get product</td>\n",
       "      <td>see food product explain anyon tast obvious wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score                       Summary  \\\n",
       "44856      5  like creami good get product   \n",
       "\n",
       "                                                    Text  \n",
       "44856  see food product explain anyon tast obvious wo...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counter is subclass of dict\n",
    "from collections import Counter\n",
    "# we will update this counter whenever needed\n",
    "counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397917,)\n",
      "(397917,)\n"
     ]
    }
   ],
   "source": [
    "# get summary and text from train data\n",
    "summary = train_data['Summary']\n",
    "print(summary.shape)\n",
    "text = train_data['Text']\n",
    "print(text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get word count from summaries of all train data and update to the counter\n",
    "for line in summary.iteritems():\n",
    "    counter.update(str(line[1]).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get word count from text data of train data and update the counter\n",
    "for line in text.iteritems():\n",
    "    counter.update(str(line[1]).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621560"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77092"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter['best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 212309), ('tast', 207138)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568454"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviews_sst.shape[0]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{'1': 52268, '2': 29769, '3': 42640, '4': 80655, '5': 363122}\n"
     ]
    }
   ],
   "source": [
    "score_counts = [sum(reviews_sst['Score'] == 1), \\\n",
    "                sum(reviews_sst['Score'] == 2), \\\n",
    "                sum(reviews_sst['Score'] == 3), \\\n",
    "                sum(reviews_sst['Score'] == 4), \\\n",
    "                sum(reviews_sst['Score'] == 5)]\n",
    "scores = dict(zip(list('12345'), score_counts))\n",
    "print(sum(score_counts) == rows)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52268, 29769, 42640, 80655, 363122)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many reviews are there that has rating\n",
    "scores['1'], scores['2'], scores['3'], scores['4'], scores['5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tple in train_data.itertuples():\n",
    "    score = str(tple[1])\n",
    "    summary = str(tple[2])\n",
    "    text = str(tple[3])\n",
    "    words = set(text.split())\n",
    "    words.update(summary.split())\n",
    "    for word in words:\n",
    "        if word in word_count:\n",
    "            word_count[word].update(score)\n",
    "        else:\n",
    "            word_count[word] = Counter(score)\n",
    "\n",
    "# the following code should be used if you want to maintain word frequecy instead of word occurance in a document.\n",
    "\n",
    "# for word in summary.split():\n",
    "#     if word in word_count:\n",
    "#         word_count[word].update(score)\n",
    "#     else:\n",
    "#         word_count[word] = Counter(score)\n",
    "# for word in text.split():\n",
    "#     if word in word_count:\n",
    "#         word_count[word].update(score)\n",
    "#     else:\n",
    "#         word_count[word] = Counter(score)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73500"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'5': 3998, '4': 1470, '3': 1295, '1': 1258, '2': 1018})\n",
      "Counter({'5': 94356, '4': 16732, '3': 5759, '1': 3480, '2': 2971})\n"
     ]
    }
   ],
   "source": [
    "#   word_count represents how many reviews(of specific score) that a perticular word occured. \n",
    "# It did't consider the case that the word occurred more than once in a single review. \n",
    "\n",
    "\n",
    "print(word_count['stick'])\n",
    "print(word_count['great'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Naive Bayes (Bernoulli model)  with our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample_test = test_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44856</th>\n",
       "      <td>5</td>\n",
       "      <td>like creami good get product</td>\n",
       "      <td>see food product explain anyon tast obvious wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280988</th>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>great soft tasti better expect perfect loaf ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309808</th>\n",
       "      <td>5</td>\n",
       "      <td>perfect</td>\n",
       "      <td>fun littl gift share sunshin co worker friend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135195</th>\n",
       "      <td>5</td>\n",
       "      <td>great natur dog food</td>\n",
       "      <td>shelti love food 6 year old shelti allergi fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15138</th>\n",
       "      <td>5</td>\n",
       "      <td>hot cocoa cup</td>\n",
       "      <td>great price 24 count dad love gift sinc love h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score                       Summary  \\\n",
       "44856       5  like creami good get product   \n",
       "280988      5                          good   \n",
       "309808      5                       perfect   \n",
       "135195      5          great natur dog food   \n",
       "15138       5                 hot cocoa cup   \n",
       "\n",
       "                                                     Text  \n",
       "44856   see food product explain anyon tast obvious wo...  \n",
       "280988  great soft tasti better expect perfect loaf ev...  \n",
       "309808  fun littl gift share sunshin co worker friend ...  \n",
       "135195  shelti love food 6 year old shelti allergi fee...  \n",
       "15138   great price 24 count dad love gift sinc love h...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Things that we will do to test our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. We will consider scores (1,2) as NEGATIVE and (4,5) as POSITIVE and we will ignore reviews that has score 3.\n",
    " 2. ie., we will consider scores(1,2,4,5) while building Confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___TP : (true positives)___ : # of reviews that are predicted POSITIVE and it is TRUE.\n",
    " \n",
    "        ie., # of POSITIVE reviews that are predicted correctly (as POSITIVE)\n",
    "___FP : (false positives)___ : # of reviews that are predicted as POSITIVE and it is FALSE.__(error)__\n",
    "    \n",
    "         ie., # of NEGATIVE reviews that are predicted incorrectly ( as POSITIVE)\n",
    "___FN : (flase negatives)___ : # of reviews that are predicted as NEGATIVE and it is FALSE.__(error)__\n",
    " \n",
    "         ie., # of POSITIVE reviews that are predicted incorrectly ( as NEGATIVE)\n",
    "___TN : (true negative)___ : # of revies that are predicted as NEGATIVE and it is TRUE.\n",
    "\n",
    "        ie., # of NEGATIVE reviews that are predicted correctly(as NEGATIVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRECISION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ___  Out of all those reviews that you are predicted as +ve, HOW PRECISE ARE YOU ..?___\n",
    "\n",
    "+ #of reviews that our model predicted as +ve = reviews that are (correctly predicted as +Ve) + ( incorrectly predicted as  +Ve)\n",
    "+ #of times you correctly predicted as +Ve = TPs\n",
    "\n",
    "$precision = \\frac{TPs} {TPs+FPs}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ___Out of all those +Ve reviews, how many times you recalled(predicted) them correcly (positive).___ \n",
    "\n",
    "+ #of reviews that are +ve = +Ve reviews that are (correctly predicted as +Ve) + ( incorrectly predicted as  -Ve)\n",
    "+ #of times you correctly predicted as +Ve = TPs\n",
    "\n",
    "$recall = \\frac{TPs} {TPs + FNs}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29931686028491017"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to get probability\n",
    "def prob(word, score):\n",
    "    return (word_count[word][score] if word in word_count else 0 + 1)/(scores[score] + 2)\n",
    "prob('like','4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> posterior $ \\alpha$ (prior $\\times$ likelihood)\n",
    "\n",
    "+ but, since our data is imbalanced (80% are positive reviews), we will make prior as constant(0.5). ie., we are basically ignore that prior term.\n",
    "\n",
    "> posterior $ \\alpha $ likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood(words, score):\n",
    "    likelihood = 1\n",
    "    for word in words:\n",
    "        likelihood = likelihood * prob(word, score)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_confusion_matrix(predicted, actual):\n",
    "#     print(predicted, actual)\n",
    "    # change this score into positive and negative\n",
    "    predicted = 'positive' if 4<=predicted<=5 else 'negative'\n",
    "    actual = 'positive' if 4<=actual<=5 else 'negative'\n",
    "\n",
    "#     print(predicted, actual)\n",
    "    if predicted is actual and actual is 'positive':\n",
    "        # update true positives\n",
    "        confusion_matrix.update({'TP':1})\n",
    "    elif predicted is actual and actual is 'negative':\n",
    "        # update true negatives\n",
    "        confusion_matrix.update({'TN':1})\n",
    "    elif predicted is not actual and actual is 'positive':\n",
    "        # update false negatives\n",
    "        confusion_matrix.update({'FN':1})\n",
    "    elif predicted is not actual and actual is 'negative':\n",
    "        # update false positives\n",
    "        confusion_matrix.update({'FP':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# intialize confusion matrix\n",
    "confusion_matrix = Counter()\n",
    "\n",
    "for row in test_data.itertuples():\n",
    "    score, summery, text = row[1:]\n",
    "    # just getting all words at one place ( in a set )\n",
    "    words = set(str(text).split())\n",
    "    words.update(str(summery).split())\n",
    "    # get all likelihoods of a review having some score into this list\n",
    "    probs = list()\n",
    "    for rating in list('12345'):\n",
    "        probs.append(likelihood(words, rating))\n",
    "    # store our predicted score into pred_score variable\n",
    "    pred_score = np.argmax(probs)+1 \n",
    "    \n",
    "    # update the confusion matrix for reviews that are not having score as 3.\n",
    "    if score != 3:\n",
    "        update_confusion_matrix(pred_score, score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'FN': 29303, 'FP': 2757, 'TN': 22049, 'TP': 103628})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7795623293287495"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = confusion_matrix['TP']/(confusion_matrix['TP'] + confusion_matrix['FN'])\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  PRECISION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ precision  = \\frac{TP} {TP + FP} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9740846923908446\n"
     ]
    }
   ],
   "source": [
    "precision = confusion_matrix['TP']/(confusion_matrix['TP'] + confusion_matrix['FP'])\n",
    "print('Precision: {}'.format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECALL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ recall = \\frac{TP}{TP + FN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.7795623293287495\n"
     ]
    }
   ],
   "source": [
    "recall = confusion_matrix['TP']/(confusion_matrix['TP']+confusion_matrix['FN'])\n",
    "print('recall: {}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of our model (F score as metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We use $F_1$ score or simply F-score as our accuracy with testing data\n",
    "+ basically $F_1$ score is _harmonic mean_ of _precision_ and _recall_\n",
    "\n",
    "$F_1 = 2 . \\frac{precision . recall}{precision + recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score : 0.866034866034866\n"
     ]
    }
   ],
   "source": [
    "f_score = 2*(precision*recall)/(precision+recall)\n",
    "print('F score : {}'.format(f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
